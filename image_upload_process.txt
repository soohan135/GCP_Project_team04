[이미지 업로드 및 분석 처리 과정 상세 설명]

이 문서는 사용자 앱에서 사진을 업로드하고, 서버(Cloud Run)와 AI 서비스를 거쳐 결과가 다시 앱으로 전달되는 전체 과정을 설명합니다.

---

1. 이미지 선택 및 업로드 (Client App - Path A & B 시작)
   - 사용자가 앱의 홈 화면(HomeScreen)에서 파손된 차량 사진을 선택합니다.
   - 앱은 `StorageService`를 통해 두 가지 작업을 **동시에(병렬로)** 수행합니다.
     1. **Path A (직접 호출)**: 속도를 위해 앱이 직접 AI 서비스(`repair-ai-service`)에 분석을 요청합니다.
     2. **Path B (파일 업로드)**: Firebase Storage의 `crashed_car_picture/` 경로에 이미지를 업로드합니다.
   
   - **왜 두 가지 경로를 모두 사용하나요?**
     - **Path A의 목적 (속도)**: Storage에 파일을 올리고 서버가 감지할 때까지 기다리면 시간이 오래 걸립니다. 사용자가 결과를 **즉시** 확인할 수 있도록 지름길(Direct Call)을 사용합니다.
     - **Path B의 목적 (보존)**: 견적 이력을 남기려면 **사진 파일 자체의 저장**이 필수적입니다. 이 과정에서 트리거되는 서버 로직(2번 과정)은 앱이 비정상 종료되더라도 분석 기록을 남기는 **이중 안전장치(Backup)** 역할을 합니다.

   - **Path A와 Path B가 동시에 실행되면 AI 요청이 두 번 가게 되나요? 괜찮나요?**
     - **네, 두 번 요청됩니다.** (Double Request)
     - 이는 의도된 설계로, **"비용을 조금 더 쓰더라도 속도와 안정성을 최우선으로 하겠다"**는 전략입니다.
     - **Trade-off (장단점)**:
       - **장점**: 사용자는 기다림 없이 즉시 결과를 보고(Path A), 앱이 꺼져도 데이터는 안전하게 보존됨(Path B).
       - **단점**: AI 서비스 호출 비용이 2배로 발생할 수 있음.
     - (참고: 일반적으로는 서버에서 '이미 분석된 파일인지 확인'하는 로직을 추가하여 중복을 방지하지만, 현재 구조는 확실한 처리를 위해 중복을 허용하고 있습니다.)

   - **호출이 두 번 되면 결과도 두 번 오나요?**
     - **아니요, 결과는 하나만 처리됩니다.** (First Win)
     - 앱(`_listenForAnalysisResult`)은 가장 먼저 도착한 유효한 분석 결과(주로 Path A)를 수신하는 순간, **즉시 연결을 끊고(Subscription Cancel) 화면에 결과를 표시**합니다.
     - 따라서 나중에 도착한 Path B의 결과는 앱이 이미 듣고 있지 않으므로 **무시**됩니다. 사용자에게는 중복 현상 없이 깔끔하게 한 번만 결과가 보입니다.

2. Cloud Run 서버 트리거 (Server - Path B 계속)
   - **Path B의 후속 작업**입니다.
   - Firebase Storage에 이미지가 저장되는 순간, 이를 감지(Event Trigger)하여 자동으로 `server` 폴더의 코드(`analyze-crashed-car` 함수)가 실행됩니다.
   - 이 서버 코드는 앱의 직접 호출(Path A)과는 별개로, 업로드된 파일을 감지하여 AI 서비스에 분석을 다시 요청합니다. (이중 안전장치 역할)

3. AI 분석 요청 (Server -> AI Service)
   - 실행된 서버 코드는 인증 토큰을 생성한 뒤, `repair-ai-service`라는 이름의 외부 AI 서버에 이미지를 전송하여 분석을 요청합니다.
   - 요청 시 차량 모델 정보(기본값 unknown)와 사용자 ID(UID)가 함께 전송됩니다.

4. 분석 결과 반환 및 저장
   - AI 서버는 이미지의 파손 부위(부품), 손상 유형, 예상 수리 견적 비용을 분석하여 반환합니다.
   - 분석된 결과 데이터(손상 부위, 수리비 범위, 분석된 이미지 URL 등)는 앱이 접근할 수 있는 데이터베이스(Firestore의 `damage_analyses` 컬렉션 또는 `users/{uid}/estimate_history`)에 저장됩니다.

5. 결과 수신 및 화면 표시 (Application)
   - **실시간 감지 원리 (Firestore Snapshot Listener)**:
     앱은 단순히 기다리는 것이 아니라, `FirebaseFirestore`의 **실시간 리스너**(`snapshots().listen(...)`) 기능을 사용해 데이터베이스의 `damage_analyses` 컬렉션을 계속 지켜보고(Listening) 있습니다.
     이는 문자 메시지가 오면 알림이 뜨는 것과 비슷하게, 앱이 데이터베이스에 새로운 저장 공간이 생기는지 실시간으로 구독(Subscribe)하고 있는 상태를 의미합니다.
   
   - **데이터 감지 및 매칭**:
     서버가 AI 분석 결과를 `damage_analyses`에 저장하는 **그 즉시(Real-time)**, Firestore 서버는 연결된 앱에게 "새로운 데이터가 도착했다"는 신호를 보냅니다.
     앱은 방금 도착한 데이터가 내가 요청한 시간 이후에 생성된 것인지 확인하여, 맞다면 나의 분석 결과로 받아들입니다.

   - **화면 갱신**:
     앱은 감지된 데이터를 바탕으로:
     1) 영어로 된 부품명(예: 'Front bumper')을 한글('앞 범퍼')로 변환하고,
     2) 숫자만 있는 금액을 보기 편한 금액 범위(예: ₩150,000 ~ ₩200,000)로 포맷팅한 뒤,
     3) `setState`를 통해 사용자 화면을 '분석 중'에서 '견적 분석 완료' 화면으로 **자동으로 변경**합니다. 사용자가 새로고침을 누를 필요가 없습니다.

---
요약:
App(이미지 전송) 
  -> Firebase Storage 저장 
  -> Cloud Run 자동 실행 
  -> AI Service 분석 
  -> 결과 DB 저장 
  -> App(결과 감지 및 표시)
